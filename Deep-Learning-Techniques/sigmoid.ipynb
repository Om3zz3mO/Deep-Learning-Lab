{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def accuracy(y_tst, y_predicted):\n",
        "    acc = np.sum(y_tst == y_predicted) / len(y_tst)\n",
        "    return acc\n",
        "\n",
        "def log_function(sample_size, y_trn, y_predicted):\n",
        "    log_summation = np.sum(y_trn * np.log(y_predicted)\n",
        "                           + (1 - y_trn) * np.log(1 - y_predicted))\n",
        "    cost = - 1 / sample_size * log_summation\n",
        "    return cost\n",
        "\n",
        "def sigmoid(linear_function):\n",
        "    sgm = 1 / (1 + np.exp(-linear_function))\n",
        "    return sgm\n",
        "\n",
        "class LogisticRegression:\n",
        "\n",
        "    def __init__(self, alpha=0.1, n_iter=1000):\n",
        "        self.alpha = alpha\n",
        "        self.n_iter = n_iter\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.info = []\n",
        "\n",
        "    def __repr__(self):\n",
        "        df = pd.DataFrame.from_dict(self.info)\n",
        "        pd.set_option('display.max_columns', None)\n",
        "        df.set_index('Iteration', inplace=True)\n",
        "        return f'\\n ---------- \\n Training Model Coefficients - ' \\\n",
        "               + f'verify the minimum cost: \\n ----------\\n {df}'\n",
        "\n",
        "    def fit(self, x_trn, y_trn):\n",
        "        n_samples, n_features = x_trn.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "        temp_dict = {}\n",
        "        for iteration in range(self.n_iter):\n",
        "            linear_model = self.linear_function(x_trn)\n",
        "            y_predicted = sigmoid(linear_model)\n",
        "            cost = log_function(n_samples, y_trn, y_predicted)\n",
        "            residuals = y_predicted - y_trn\n",
        "            self.gradient_descent(n_samples, x_trn, residuals)\n",
        "            temp_dict['Iteration'] = iteration\n",
        "\n",
        "            for i in range(len(self.weights)):\n",
        "                temp_dict['W' + str(i)] = self.weights[i]\n",
        "\n",
        "            temp_dict['Bias'] = self.bias\n",
        "            temp_dict['Cost'] = cost\n",
        "            self.info.append(temp_dict.copy())\n",
        "\n",
        "    def linear_function(self, x):\n",
        "        return np.dot(x, self.weights) + self.bias\n",
        "\n",
        "    def gradient_descent(self, n_samples, x_trn, residuals):\n",
        "        weight_derivative = (1 / n_samples) * np.dot(x_trn.T, residuals)\n",
        "        bias_derivative = (1 / n_samples) * np.sum(residuals)\n",
        "        self.weights -= self.alpha * weight_derivative\n",
        "        self.bias -= self.alpha * bias_derivative\n",
        "\n",
        "    def predict(self, x_tst):\n",
        "        linear_model = self.linear_function(x_tst)\n",
        "        sigmoid_function = sigmoid(linear_model)\n",
        "        y_predicted = [1 if i > 0.5 else 0 for i in sigmoid_function]\n",
        "        return y_predicted\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    bc = datasets.load_breast_cancer()\n",
        "    X, y = bc.data, bc.target\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                        test_size=0.2,\n",
        "                                                        random_state=1234)\n",
        "\n",
        "    logistic_classifier = LogisticRegression(alpha=0.00001,\n",
        "                                             n_iter=1000)\n",
        "    logistic_classifier.fit(X_train, y_train)\n",
        "    predictions = logistic_classifier.predict(X_test)\n",
        "    print(logistic_classifier)\n",
        "    print(\"----------\\nLR classification accuracy:\",\n",
        "          accuracy(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_9rFafeZCAu",
        "outputId": "e1def3f8-5d22-4c05-ad8a-0e2c806c9be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ---------- \n",
            " Training Model Coefficients - verify the minimum cost: \n",
            " ----------\n",
            "                  W0        W1        W2        W3            W4            W5  \\\n",
            "Iteration                                                                       \n",
            "0          0.000007  0.000017  0.000036 -0.000317  1.016919e-07 -2.021637e-08   \n",
            "1          0.000045  0.000075  0.000283  0.001017  4.027614e-07  1.976795e-07   \n",
            "2          0.000011  0.000040  0.000054 -0.001343  2.476329e-07 -1.227666e-07   \n",
            "3          0.000081  0.000142  0.000499  0.001327  7.648824e-07  3.190927e-07   \n",
            "4          0.000049  0.000110  0.000288 -0.000897  6.278010e-07  1.996203e-08   \n",
            "...             ...       ...       ...       ...           ...           ...   \n",
            "995        0.005041  0.008652  0.029695  0.015600  5.112721e-05 -8.071805e-06   \n",
            "996        0.005044  0.008655  0.029709  0.015603  5.115044e-05 -8.095912e-06   \n",
            "997        0.005046  0.008659  0.029723  0.015605  5.117365e-05 -8.120030e-06   \n",
            "998        0.005049  0.008662  0.029738  0.015607  5.119683e-05 -8.144160e-06   \n",
            "999        0.005052  0.008665  0.029752  0.015609  5.122000e-05 -8.168301e-06   \n",
            "\n",
            "                     W6            W7            W8            W9  \\\n",
            "Iteration                                                           \n",
            "0         -1.554758e-07 -8.183442e-08  1.978791e-07  8.263945e-08   \n",
            "1         -7.798668e-08 -3.419782e-08  7.695899e-07  2.915481e-07   \n",
            "2         -5.193387e-07 -2.746138e-07  4.856035e-07  2.106073e-07   \n",
            "3         -2.644048e-07 -1.303643e-07  1.463745e-06  5.614252e-07   \n",
            "4         -6.858835e-07 -3.598055e-07  1.213600e-06  4.919707e-07   \n",
            "...                 ...           ...           ...           ...   \n",
            "995       -6.803070e-05 -3.020617e-05  1.005945e-04  4.007343e-05   \n",
            "996       -6.809345e-05 -3.023249e-05  1.006419e-04  4.009290e-05   \n",
            "997       -6.815619e-05 -3.025880e-05  1.006893e-04  4.011236e-05   \n",
            "998       -6.821892e-05 -3.028511e-05  1.007366e-04  4.013181e-05   \n",
            "999       -6.828165e-05 -3.031142e-05  1.007839e-04  4.015124e-05   \n",
            "\n",
            "                    W10       W11       W12       W13           W14  \\\n",
            "Iteration                                                             \n",
            "0         -2.112275e-07  0.000002 -0.000002 -0.000065  1.008670e-08   \n",
            "1          5.781304e-07  0.000006  0.000004 -0.000018  3.398555e-08   \n",
            "2         -8.663864e-07  0.000004 -0.000007 -0.000218  2.612108e-08   \n",
            "3          7.318060e-07  0.000011  0.000005 -0.000097  6.585229e-08   \n",
            "4         -6.273614e-07  0.000010 -0.000005 -0.000288  5.921080e-08   \n",
            "...                 ...       ...       ...       ...           ...   \n",
            "995        4.478085e-05  0.000686  0.000049 -0.010427  3.989541e-06   \n",
            "996        4.482003e-05  0.000687  0.000049 -0.010430  3.991070e-06   \n",
            "997        4.485920e-05  0.000687  0.000049 -0.010433  3.992596e-06   \n",
            "998        4.489836e-05  0.000687  0.000049 -0.010436  3.994121e-06   \n",
            "999        4.493749e-05  0.000688  0.000049 -0.010439  3.995643e-06   \n",
            "\n",
            "                    W15           W16           W17           W18  \\\n",
            "Iteration                                                           \n",
            "0          6.577165e-09  4.558063e-09  3.092780e-09  2.837495e-08   \n",
            "1          6.857291e-08  7.993076e-08  3.220849e-08  9.715364e-08   \n",
            "2          4.494331e-09 -5.442807e-09  2.193964e-09  7.310063e-08   \n",
            "3          1.221850e-07  1.393373e-07  5.688479e-08  1.875228e-07   \n",
            "4          6.300166e-08  6.013958e-08  2.915057e-08  1.670426e-07   \n",
            "...                 ...           ...           ...           ...   \n",
            "995       -7.644693e-07 -1.841256e-06  6.282244e-07  1.205327e-05   \n",
            "996       -7.710771e-07 -1.849475e-06  6.265670e-07  1.205871e-05   \n",
            "997       -7.776890e-07 -1.857699e-06  6.249080e-07  1.206415e-05   \n",
            "998       -7.843051e-07 -1.865928e-06  6.232476e-07  1.206958e-05   \n",
            "999       -7.909252e-07 -1.874162e-06  6.215857e-07  1.207500e-05   \n",
            "\n",
            "                    W19       W20       W21       W22       W23           W24  \\\n",
            "Iteration                                                                       \n",
            "0          3.604454e-09  0.000004  0.000021  0.000016 -0.000830  1.255020e-07   \n",
            "1          1.489374e-08  0.000045  0.000097  0.000283  0.000650  5.264656e-07   \n",
            "2          8.576151e-09  0.000002  0.000048 -0.000015 -0.003008  2.976729e-07   \n",
            "3          2.830110e-08  0.000078  0.000181  0.000481  0.000211  9.961759e-07   \n",
            "4          2.267285e-08  0.000037  0.000137  0.000205 -0.003251  7.926399e-07   \n",
            "...                 ...       ...       ...       ...       ...           ...   \n",
            "995        1.179445e-06  0.005196  0.011011  0.029522 -0.019240  6.585270e-05   \n",
            "996        1.179438e-06  0.005199  0.011015  0.029536 -0.019245  6.588041e-05   \n",
            "997        1.179429e-06  0.005201  0.011019  0.029550 -0.019250  6.590809e-05   \n",
            "998        1.179420e-06  0.005204  0.011023  0.029564 -0.019256  6.593574e-05   \n",
            "999        1.179410e-06  0.005207  0.011027  0.029578 -0.019261  6.596336e-05   \n",
            "\n",
            "                    W25           W26           W27           W28  \\\n",
            "Iteration                                                           \n",
            "0         -1.271355e-07 -3.203279e-07 -1.023944e-07  2.658022e-07   \n",
            "1          3.332879e-07  3.378152e-08  7.658898e-08  1.134705e-06   \n",
            "2         -5.339646e-07 -1.126120e-06 -3.759358e-07  6.247611e-07   \n",
            "3          4.805623e-07 -1.907001e-07  4.341146e-08  2.143742e-06   \n",
            "4         -3.323207e-07 -1.289330e-06 -3.839905e-07  1.689267e-06   \n",
            "...                 ...           ...           ...           ...   \n",
            "995       -6.013693e-05 -1.401406e-04 -3.284451e-05  1.431655e-04   \n",
            "996       -6.023761e-05 -1.402977e-04 -3.288366e-05  1.432267e-04   \n",
            "997       -6.033832e-05 -1.404547e-04 -3.292282e-05  1.432878e-04   \n",
            "998       -6.043906e-05 -1.406118e-04 -3.296198e-05  1.433488e-04   \n",
            "999       -6.053983e-05 -1.407689e-04 -3.300115e-05  1.434098e-04   \n",
            "\n",
            "                    W29      Bias      Cost  \n",
            "Iteration                                    \n",
            "0          8.019011e-08  0.000001  0.693147  \n",
            "1          3.333883e-07  0.000005  0.747732  \n",
            "2          1.905747e-07  0.000003  1.011655  \n",
            "3          6.331360e-07  0.000009  1.548803  \n",
            "4          5.062814e-07  0.000008  0.936051  \n",
            "...                 ...       ...       ...  \n",
            "995        3.875700e-05  0.000677  0.258002  \n",
            "996        3.877034e-05  0.000677  0.257953  \n",
            "997        3.878366e-05  0.000677  0.257904  \n",
            "998        3.879697e-05  0.000678  0.257855  \n",
            "999        3.881026e-05  0.000678  0.257806  \n",
            "\n",
            "[1000 rows x 32 columns]\n",
            "----------\n",
            "LR classification accuracy: 0.9210526315789473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jr8HHnPpS13i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}